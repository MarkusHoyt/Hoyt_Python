{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "850eefa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Python Project/cost_of_living.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12588\\1243176279.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcost_of_living\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python Project/cost_of_living.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msalaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python Project/ds_salaries.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0msalarylevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Python Project/Levels_Fyi_Salary_Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 )\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"b\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\DSE5002\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Python Project/cost_of_living.csv'"
     ]
    }
   ],
   "source": [
    "#Mark Hoyt \n",
    "#12/10/22\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "\n",
    "cost_of_living = pd.read_csv('Python Project/cost_of_living.csv')\n",
    "salaries = pd.read_csv('Python Project/ds_salaries.csv')\n",
    "salarylevels = pd.read_csv('Python Project/Levels_Fyi_Salary_Data.csv')\n",
    "country_codes = pd.read_csv('Python Project/country_codes.csv')\n",
    "\n",
    "\n",
    "# making the dataframe more suitable for what I need if for \n",
    "# (exp. remote work doesn't matter for this probelm)\n",
    "\n",
    "salaries.dtypes\n",
    "\n",
    "#removing unneeded columns\n",
    "salaries = salaries.drop(['Unnamed: 0','remote_ratio','company_size'],axis=1)\n",
    "salaries[\"salary\"] = salaries['salary'].astype(str) +\" \"+ salaries[\"salary_currency\"]\n",
    "salaries = salaries.drop(['salary_currency'],axis=1)\n",
    "\n",
    "#making experience level easier to read\n",
    "salaries['experience_level'] = salaries['experience_level'].replace(['MI'], 'Mid Level')\n",
    "salaries['experience_level'] = salaries['experience_level'].replace(['EN'], 'Entry Level')\n",
    "salaries['experience_level'] = salaries['experience_level'].replace(['EX'], 'Executive Level')\n",
    "salaries['experience_level'] = salaries['experience_level'].replace(['SE'], 'Senior Level')\n",
    "\n",
    "#making employment type easier to read \n",
    "salaries['employment_type'] = salaries['employment_type'].replace(['FT'], 'Full Time')\n",
    "salaries['employment_type'] = salaries['employment_type'].replace(['FL'], 'Full Time')\n",
    "salaries['employment_type'] = salaries['employment_type'].replace(['CT'], 'Contract Time')\n",
    "salaries['employment_type'] = salaries['employment_type'].replace(['PT'], 'Part Time')\n",
    "\n",
    "#coverting the date\n",
    "salaries['work_year'] = pd.to_datetime(salaries['work_year'], format='%Y')\n",
    "\n",
    "#adding a new column of country codes to country names \n",
    "\n",
    "salarylevels.dtypes\n",
    "#removing unneeded columns\n",
    "salarylevels = salarylevels.drop(['level', 'rowNumber', 'gender','tag', 'Bachelors_Degree', 'Highschool', 'Some_College', 'Race_Asian', 'Race_White', 'Race_Black', 'Race_Two_Or_More', 'Race_Hispanic', 'Race', 'Education', 'yearsatcompany','dmaid'],axis=1)\n",
    "\n",
    "# converting time stamp to proper type\n",
    "salarylevels['timestamp'] = pd.to_datetime(salarylevels['timestamp'], format='%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "#getting rid or unapplicable jobs\n",
    "names=['Software Engineer','Software Engineer Manager', 'Technical Program Manager', 'Sales', 'Marketing', 'Human Resources', 'Mechanical Engineer', 'Product Designer', 'Product Manager', 'Solution Architect', 'Hardware Engineer', 'Software Engineering Manager', 'Recruiter', 'Management Consultant', 'Business Analyst']\n",
    "salarylevels = salarylevels[~salarylevels.title.isin(names)]\n",
    "salarylevels = salarylevels.drop(523)\n",
    "\n",
    "# splitting location column of salarylevels\n",
    "location = salarylevels[\"location\"].str.split(\",\", n = 1, expand = True)\n",
    "salarylevels[\"City/region\"]= location[0]\n",
    "salarylevels[\"State/Country\"]= location[1]\n",
    "\n",
    "#removing unneeded column \n",
    "salarylevels = salarylevels.drop(['location'],axis=1)\n",
    "\n",
    "#moving to first index\n",
    "first_column = salarylevels.pop('State/Country')\n",
    "salarylevels.insert(1, 'State/Country', first_column)\n",
    "\n",
    "cost_of_living.dtypes\n",
    "\n",
    "# split value  location columns\n",
    "location2 = cost_of_living[\"City\"].str.split(\",\", n = 1, expand = True)\n",
    "cost_of_living[\"City/region\"]= location2[0]\n",
    "cost_of_living[\"State/Country\"]= location2[1]\n",
    "\n",
    "#removing unneeded column \n",
    "cost_of_living = cost_of_living.drop(['City'],axis=1)\n",
    "\n",
    "# creating a df in my desired index\n",
    "desiredindex = cost_of_living.loc[(cost_of_living[\"Cost of Living Plus Rent Index\"] > 50) & (cost_of_living[\"Cost of Living Plus Rent Index\"] < 100.99) & (cost_of_living[\"Groceries Index\"] < 100.99) & (cost_of_living[\"Local Purchasing Power Index\"] > 99.99)]\n",
    "\n",
    "# graph for desired index \n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.relplot(\n",
    "    data=desiredindex, x=\"Cost of Living Plus Rent Index\", y=\"Local Purchasing Power Index\", hue=\"State/Country\",\n",
    ")\n",
    "\n",
    "# I am now going to take the top purchasing power and lowest COL + rent index countrys and make a new dataframe\n",
    "topindex = desiredindex.loc[(desiredindex[\"Local Purchasing Power Index\"] > 140) & (desiredindex[\"Cost of Living Plus Rent Index\"] < 80)]\n",
    "\n",
    "location3 = topindex[\"State/Country\"].str.split(\",\", n = 1, expand = True)\n",
    "topindex[\"State\"]= location3[0]\n",
    "topindex[\"Country\"]= location3[1]\n",
    "\n",
    "#removing unneeded column \n",
    "topindex = topindex.drop(['State/Country'],axis=1)\n",
    "\n",
    "#cross refrencing my top indexes locations with salarylevels locations to find matching jobs\n",
    "topindex_salary = salarylevels.loc[(salarylevels[\"State/Country\"] == ' CA') & (salarylevels[\"City/region\"] == 'Fremont')]\n",
    "topindex_salary2 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' CA') & (salarylevels[\"City/region\"] == 'San Jose')]\n",
    "topindex_salary3 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' FL')]\n",
    "topindex_salary4 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' MI') & (salarylevels[\"City/region\"] == 'Ann Arbor')]\n",
    "topindex_salary5 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' NC') & (salarylevels[\"City/region\"] == 'Charlotte')]\n",
    "topindex_salary6 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' NC') & (salarylevels[\"City/region\"] == 'Raleigh')]\n",
    "topindex_salary7 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' NJ') & (salarylevels[\"City/region\"] == 'Jersey City')]\n",
    "topindex_salary8 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' OH') & (salarylevels[\"City/region\"] == 'Columbus')]\n",
    "topindex_salary9 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' TX') & (salarylevels[\"City/region\"] == 'Dallas')]\n",
    "topindex_salary10 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' TX') & (salarylevels[\"City/region\"] == 'Austin')]\n",
    "topindex_salary11 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' TX') & (salarylevels[\"City/region\"] == 'Houston')]\n",
    "topindex_salary12 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' UT')]\n",
    "topindex_salary13 = salarylevels.loc[(salarylevels[\"State/Country\"] == ' WA') & (salarylevels[\"City/region\"] == 'Seattle')]\n",
    "\n",
    "frame = [topindex_salary, topindex_salary2, topindex_salary3, topindex_salary4, topindex_salary5, topindex_salary6, topindex_salary7, topindex_salary8, topindex_salary9, topindex_salary10, topindex_salary11, topindex_salary12, topindex_salary13]\n",
    "crossrefrence = pd.concat(frame)\n",
    "\n",
    "# I do not have a doctoare so getting rid of this\n",
    "crossrefrence = crossrefrence.loc[crossrefrence[\"Doctorate_Degree\"] == 0]\n",
    "crossrefrence.rename(columns = {'timestamp':'Job Date'}, inplace = True)\n",
    "\n",
    "#combining state and country columns \n",
    "crossrefrence[\"Location\"] = crossrefrence['City/region'].astype(str) +\",\"+ crossrefrence[\"State/Country\"]\n",
    "\n",
    "crossrefrence = crossrefrence.drop(['State/Country'],axis=1)\n",
    "crossrefrence = crossrefrence.drop(['City/region'],axis=1)\n",
    "\n",
    "#moving to first index\n",
    "first_column = crossrefrence.pop('Location')\n",
    "crossrefrence.insert(1, 'Location', first_column)\n",
    "\n",
    "#graphing crossrefrence df\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.relplot(\n",
    "    data=crossrefrence, x=\"Job Date\", y=\"totalyearlycompensation\", hue=\"Location\",\n",
    ")\n",
    "\n",
    "#showing stats of each location\n",
    "avgsalaries = crossrefrence.groupby('Location')['totalyearlycompensation'].agg([np.mean, np.median, np.std])\n",
    "print(avgsalaries)\n",
    "\n",
    "#graphing this \n",
    "ax = sns.lineplot(x='Location', y='mean'\n",
    "             ,data=avgsalaries)\n",
    "plt.xticks(rotation=45)\n",
    "ax.yaxis.set_major_formatter('${x:1.0f}')\n",
    "plt.title('Average salary by location')\n",
    "plt.ylabel('Mean Pay')\n",
    "plt.xlabel('Location')\n",
    "\n",
    "topindex[\"Location\"] = topindex['City/region'].astype(str) +\",\"+ topindex[\"State\"]\n",
    "first_column = topindex.pop('Location')\n",
    "topindex.insert(1, 'Location', first_column)\n",
    "topindex = topindex.drop(['City/region'],axis=1)\n",
    "topindex = topindex.drop(['State'],axis=1)\n",
    "topindex = topindex.drop(['Country'],axis=1)\n",
    "topindex = topindex.drop(['Rank'],axis=1)\n",
    "#merging these dataframes \n",
    "salaries_index = avgsalaries.merge(topindex, how = 'inner', on = ['Location'])\n",
    "print(salaries_index)\n",
    "#cross refrencing the results of the above code with salaries to find my top five places to live\n",
    "# my top 5 are: 5.) Charlotte, NC, 4.) Dallas, TX, 3.) Raleigh, NC, 2.) Columbus, OH and #1.) is Houston, TX \n",
    "# Salaries_index has the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34f4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
